{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpgrl1yMec2q"
   },
   "source": [
    "Welcome to Pupper lovers!! by:  Taylor Kramer, Manisha Jaiswal, and John Santiago\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Yu2xgrQXeiOU"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4fc4f355048b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10, mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7owyDRR8fZ0v"
   },
   "outputs": [],
   "source": [
    "#Preparing datasets\n",
    "\n",
    "# !!!!!!!!!! when making full dataset: this took me 50 minutes to run, so conservatively expect it to take around an hour!!!!!!!!!\n",
    "#(once this step is done avoid rerunning this every time since it will take a while to create the datasets every time)\n",
    "\n",
    "def url_to_image(url):\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "trainurl = 'https://github.com/johnmburt/projects/blob/master/AWS/sagemaker_dog_breed_id/dog_breeds_all_fold_1_train.lst?raw=true'\n",
    "testurl = 'https://github.com/johnmburt/projects/blob/master/AWS/sagemaker_dog_breed_id/dog_breeds_all_fold_1_test.lst?raw=true'\n",
    "traindf = pd.read_csv(trainurl, sep='\\t', usecols=[2])\n",
    "testdf = pd.read_csv(testurl, sep='\\t', usecols=[2])\n",
    "trainlist = traindf.values.tolist()\n",
    "testlist = testdf.values.tolist()\n",
    "\n",
    "#choose how much of the dataset to use (great for when we are still writing the code for the model)\n",
    "\n",
    "percentdatasetused = 0.06 # use this to change dataset sizes for when we aren't running full model!!!!!!!!!!!!!!!!!!!!!\n",
    "trainnum = int(len(trainlist)*percentdatasetused)\n",
    "testnum = int(len(testlist)*percentdatasetused)\n",
    "print(trainnum, testnum)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "cnt = 0\n",
    "for i in range(trainnum):\n",
    "  string = trainlist[i][0]\n",
    "  url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/thumbnails/\"+string\n",
    "  img = url_to_image(url)\n",
    "  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "  gray = np.float32(gray)\n",
    "  X_train.append(gray)\n",
    "  label = string[string.find(\"-\") + 1: string.find(\"/\")]\n",
    "  y_train.append(label)\n",
    "  cnt = cnt + 1\n",
    "  print(cnt)\n",
    "cnt = 0\n",
    "for j in range(testnum):\n",
    "  string = testlist[j][0]\n",
    "  url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/thumbnails/\"+string\n",
    "  img = url_to_image(url)\n",
    "  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "  gray = np.float32(gray)\n",
    "  X_test.append(gray)\n",
    "  label = string[string.find(\"-\") + 1: string.find(\"/\")]\n",
    "  y_test.append(label)\n",
    "  cnt = cnt + 1\n",
    "  print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PE0sAtCEcbUF",
    "outputId": "eaa9ae4a-e7e1-45c3-b17f-e9d839ff97da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have data for 120 /120 different dog breeds in train set.\n",
      "we have data for 107 /120 different dog breeds in test set.\n"
     ]
    }
   ],
   "source": [
    "# print(len(X_train),len(y_train))\n",
    "# print(len(X_test),len(y_test))\n",
    "\n",
    "settrain = set(y_train)\n",
    "settest = set(y_test)\n",
    "uniqtrain = len(settrain)\n",
    "uniqtest = len(settest)\n",
    "print(\"we have data for\",str(uniqtrain),\"/120 different dog breeds in train set.\")\n",
    "print(\"we have data for\",str(uniqtest),\"/120 different dog breeds in test set.\")\n",
    "\n",
    "# turn dog breeds into numbers where each dog class is identified as an integer\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(list(settrain))\n",
    "traintargets = le.transform(y_train)\n",
    "testtargets = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qF58q_1WOTs"
   },
   "outputs": [],
   "source": [
    "#make data insertable into model\n",
    "Xtrain = tf.convert_to_tensor(X_train)\n",
    "ytrain = tf.convert_to_tensor(traintargets)\n",
    "Xtest = tf.convert_to_tensor(X_test)\n",
    "ytest = tf.convert_to_tensor(testtargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pp5MsFuQcnah",
    "outputId": "fa783e95-bf2d-4a77-dadd-8965317d75f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 13.5565 - accuracy: 0.0072\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 14.3573 - accuracy: 0.0069\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 14.5315 - accuracy: 0.0138\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 14.7683 - accuracy: 0.0122\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 14.5695 - accuracy: 0.0106\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 105)               1720425   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 105)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 210)               22260     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 210)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 120)               25320     \n",
      "=================================================================\n",
      "Total params: 1,768,005\n",
      "Trainable params: 1,768,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model (below is an example from one of our assignments)\n",
    "\n",
    "simple_layers = [\n",
    "                 tf.keras.layers.Flatten(),\n",
    "                 tf.keras.layers.Dense(105, activation=\"relu\"),\n",
    "                 tf.keras.layers.Dropout(0.04),\n",
    "                 tf.keras.layers.Dense(210, activation=\"relu\"),\n",
    "                 tf.keras.layers.Dropout(0.0035),\n",
    "                 tf.keras.layers.Dense(120),\n",
    "]\n",
    "\n",
    "simple_model = Sequential(simple_layers)\n",
    "simple_model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#train model\n",
    "simple_model.fit(Xtrain, ytrain, epochs=5)\n",
    "simple_model.summary()\n",
    "\n",
    "\n",
    "#TODO: test model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXovFzePfC_R"
   },
   "outputs": [],
   "source": [
    "#TODO: show results in some fun way (maybe use brand new dog picture from online)\n",
    "\n",
    "#maybe we can test our model using a brand new photo that the model hasn't seen yet? using .predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nBp0uAu84EH3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPrimary:\\n  Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao and Li Fei-Fei. Novel dataset for Fine-Grained Image Categorization. \\n  First Workshop on Fine-Grained Visual Categorization (FGVC), IEEE Conference on Computer Vision and Pattern Recognition (CVPR), \\n  2011.  [pdf]  [poster]  [BibTex]\\n\\nSecondary:\\n  J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li and L. Fei-Fei, ImageNet: A Large-Scale Hierarchical Image Database. \\n  IEEE Computer Vision and Pattern Recognition (CVPR), 2009.  [pdf]  [BibTex]\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#references:\n",
    "\n",
    "#dataset refs\n",
    "\n",
    "'''\n",
    "Primary:\n",
    "  Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao and Li Fei-Fei. Novel dataset for Fine-Grained Image Categorization. \n",
    "  First Workshop on Fine-Grained Visual Categorization (FGVC), IEEE Conference on Computer Vision and Pattern Recognition (CVPR), \n",
    "  2011.  [pdf]  [poster]  [BibTex]\n",
    "\n",
    "Secondary:\n",
    "  J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li and L. Fei-Fei, ImageNet: A Large-Scale Hierarchical Image Database. \n",
    "  IEEE Computer Vision and Pattern Recognition (CVPR), 2009.  [pdf]  [BibTex]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PupperLovers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
